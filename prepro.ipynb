{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = 'data'\n",
    "shop = 'data_se'\n",
    "# Тренировочные данные\n",
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'orders_se_test.txt'),index_col=0) # , nrows=1000\n",
    "products = pd.read_csv(os.path.join(root_data_dir, shop, 'products_se.txt'),index_col=0)\n",
    "t = data['product_id']\n",
    "data['name'] = t.replace(products['product_id'].values, products['name'].values)\n",
    "data.to_csv('data/data_se/data_name_test.txt', index=False, columns=['order_id', 'name'])\n",
    "\n",
    "# Тестовые данные\n",
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'orders_se_train.txt'),index_col=0)\n",
    "products = pd.read_csv(os.path.join(root_data_dir, shop, 'products_se.txt'),index_col=0)\n",
    "t = data['product_id']\n",
    "data['name'] = t.replace(products['product_id'].values, products['name'].values)\n",
    "data.to_csv('data/data_se/data_name_train.txt', index=False, columns=['order_id', 'name'])\n",
    "\n",
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оставим самое необходимое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(os.path.join(root_data_dir, shop, 'data_name_test.txt'))\n",
    "data_train = pd.read_csv(os.path.join(root_data_dir, shop, 'data_name_train.txt'))\n",
    "data =  pd.concat([data_test, data_train]).sort_values(by=\"order_id\")\n",
    "mas_indexet = data['name'].drop_duplicates().values\n",
    "f = open('data/data_se/mas_indexet.txt', 'w', encoding='utf-8')\n",
    "for i in mas_indexet:\n",
    "    f.write(i + \"\\n\")\n",
    "f = open('data/data_se/data_i_test.txt', 'w')\n",
    "f.write('order_id,name_id\\n')\n",
    "for d in data_test.values:\n",
    "    # Проиндексируем продукты для простоты вычислений\n",
    "    f.write(f'{d[0]},{np.where(mas_indexet == d[1])[0][0]}\\n')\n",
    "f.close()\n",
    "f = open('data/data_se/data_i_train.txt', 'w')\n",
    "f.write('order_id,name_id\\n')\n",
    "for d in data_train.values:\n",
    "    # Проиндексируем продукты для простоты вычислений\n",
    "    f.write(f'{d[0]},{np.where(mas_indexet == d[1])[0][0]}\\n')\n",
    "f.close()\n",
    "\n",
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'data_i_test.txt'))\n",
    "carts_test = data.groupby('order_id')['name_id'].apply(list).reset_index()\n",
    "\n",
    "\n",
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'data_i_train.txt'))\n",
    "max_i = data.name_id.max() + 1\n",
    "carts_train = data.groupby('order_id')['name_id'].apply(list).reset_index()\n",
    "\n",
    "carts = pd.concat([carts_test, carts_train]).sort_values(by=['order_id'])\n",
    "\n",
    "# carts_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Произведём подсчёт и сортировку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.zeros(max_i)\n",
    "for a in carts['name_id'].values:\n",
    "    for i in a:\n",
    "        stat[i]+=1\n",
    "sort_stat = stat.copy()\n",
    "sort_stat.sort()\n",
    "\n",
    "f1 = stat > 50\n",
    "f2 = stat < sort_stat[-21]\n",
    "f = f1*f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаляем лишнее (Повторения, Самые частые и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228663\n"
     ]
    }
   ],
   "source": [
    "ind = []\n",
    "result = open('data.txt', 'w')\n",
    "result.write('order_id,name_id\\n')\n",
    "for i, d in enumerate(carts.values):\n",
    "    t = []\n",
    "    for j in d[1]:\n",
    "        if f[j]:\n",
    "            t.append(j)\n",
    "    t = list(set(t))\n",
    "    if len(t) > 1:\n",
    "        for i in t:\n",
    "            result.write(f'{d[0]},{i}\\n')\n",
    "result.close()\n",
    "len_d = len(open('data.txt').readlines())\n",
    "data = pd.read_csv( 'data.txt')\n",
    "max_i = data.name_id.max() + 1\n",
    "carts = data.groupby('order_id')['name_id'].apply(list).reset_index()\n",
    "\n",
    "stat = np.zeros(max_i)\n",
    "for a in carts['name_id'].values:\n",
    "    for i in a:\n",
    "        stat[i]+=1\n",
    "sort_stat = stat.copy()\n",
    "sort_stat.sort()\n",
    "\n",
    "# Товары, встречающиеся меньше 50 раз\n",
    "f = stat > 50\n",
    "print(len_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переиндексируем полученные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.txt')\n",
    "mas_indexet = data['name_id'].drop_duplicates().values\n",
    "np.savetxt('data/data_se/i2.txt', mas_indexet.astype(int),  fmt = '%s')\n",
    "f = open('data/data_se/data_i2.txt', 'w')\n",
    "f.write('order_id,name_id\\n')\n",
    "for d in data.values:\n",
    "    f.write(f'{d[0]},{np.where(mas_indexet == d[1])[0][0]}\\n')\n",
    "f.close()\n",
    "\n",
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим на Train\\Test в соответствии с изначальным разбиением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'data_i2.txt'))\n",
    "i_test = pd.read_csv(os.path.join(root_data_dir, shop, 'data_test.txt'))['order_id'].values\n",
    "i_train = pd.read_csv(os.path.join(root_data_dir, shop, 'data_train.txt'))['order_id'].values\n",
    "i_data = data['order_id'].values\n",
    "\n",
    "id = np.intersect1d(i_data, i_test)\n",
    "result = open('data/data_se/data_i2_test.txt', 'w', encoding='utf-8')\n",
    "result.write('order_id,name_id\\n')\n",
    "for d in data.values:\n",
    "    if d[0] in id:\n",
    "        result.write(f'{d[0]},{d[1]}\\n')\n",
    "result.close()\n",
    "\n",
    "id = np.intersect1d(i_data, i_train)\n",
    "result = open('data/data_se/data_i2_train.txt', 'w', encoding='utf-8')\n",
    "result.write('order_id,name_id\\n')\n",
    "for d in data.values:\n",
    "    if d[0] in id:\n",
    "        result.write(f'{d[0]},{d[1]}\\n')\n",
    "result.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группируем и Сохраняем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'data_i2_test.txt'))\n",
    "carts_test = data.groupby('order_id')['name_id'].apply(list).reset_index()\n",
    "carts_test .to_csv('data/data_se/data_test.txt', index=False, columns=['order_id', 'name_id'])\n",
    "\n",
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'data_i2_train.txt'))\n",
    "carts_train = data.groupby('order_id')['name_id'].apply(list).reset_index()\n",
    "carts_train.to_csv('data/data_se/data_train.txt', index=False, columns=['order_id', 'name_id'])\n",
    "\n",
    "data = pd.read_csv(os.path.join(root_data_dir, shop, 'data_i2.txt'))\n",
    "carts = data.groupby('order_id')['name_id'].apply(list).reset_index()\n",
    "carts.to_csv('data/data_se/data.txt', index=False, columns=['order_id', 'name_id'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
